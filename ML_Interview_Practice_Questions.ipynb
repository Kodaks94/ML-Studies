{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eaa3b10",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Interview Practice Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4fa66",
   "metadata": {},
   "source": [
    "\n",
    "## Supervised Learning\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain the difference between Linear Regression and Logistic Regression. What types of problems are they each suitable for?\n",
    "2. What are the assumptions made by linear regression models?\n",
    "3. What are common methods to evaluate regression and classification models? Describe each briefly.\n",
    "4. Explain bias-variance tradeoff and how it affects model performance.\n",
    "\n",
    "**Programming Task: Linear Regression**\n",
    "\n",
    "Implement a linear regression model to predict house prices. Use a dataset of your choice (such as Boston Housing, if available), \n",
    "and ensure to include model evaluation metrics (e.g., Mean Squared Error and R-squared).\n",
    "\n",
    "**Programming Task: Classification with Logistic Regression**\n",
    "\n",
    "Implement a logistic regression model using Scikit-learn to classify digits from the MNIST dataset. Evaluate the model using accuracy, \n",
    "precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Linear Regression Model\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c1d38",
   "metadata": {},
   "source": [
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Describe the K-means clustering algorithm and its main limitations.\n",
    "2. What is the role of distance metrics in clustering algorithms?\n",
    "3. Explain Principal Component Analysis (PCA) and its use cases in machine learning.\n",
    "4. What are some ways to determine the optimal number of clusters?\n",
    "\n",
    "**Programming Task: K-means Clustering**\n",
    "\n",
    "Use K-means clustering on the Iris dataset and visualize the clusters. Try to determine the optimal number of clusters using \n",
    "the Elbow method.\n",
    "\n",
    "**Programming Task: PCA**\n",
    "\n",
    "Perform PCA on the Iris dataset and plot the first two principal components. Explain the variance captured by these components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-means Clustering\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813be068",
   "metadata": {},
   "source": [
    "\n",
    "## Neural Networks\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain the structure of a feed-forward neural network. How does backpropagation work in this network?\n",
    "2. What is the difference between activation functions such as ReLU, Sigmoid, and Tanh?\n",
    "3. Describe how overfitting can be prevented in neural networks.\n",
    "4. What are some advantages and disadvantages of using deep neural networks?\n",
    "\n",
    "**Programming Task: Feed-Forward Neural Network**\n",
    "\n",
    "Implement a simple feed-forward neural network using TensorFlow to classify digits from the MNIST dataset. \n",
    "Use techniques such as dropout to mitigate overfitting and evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6629e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Feed-Forward Neural Network\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c8f6",
   "metadata": {},
   "source": [
    "\n",
    "## Transformers and NLP\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. What is a transformer architecture, and how does it differ from recurrent neural networks (RNNs)?\n",
    "2. Explain the concept of self-attention in transformers and why it is effective for NLP tasks.\n",
    "3. What are common NLP tasks for which transformers are particularly well-suited?\n",
    "4. Discuss the difference between BERT and GPT architectures.\n",
    "\n",
    "**Programming Task: Text Classification**\n",
    "\n",
    "Use the Hugging Face Transformers library to fine-tune a pre-trained BERT model on a text classification task, \n",
    "such as sentiment analysis. Evaluate the model on accuracy and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c23a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Text Classification with Transformers\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119e30d",
   "metadata": {},
   "source": [
    "\n",
    "## Data Processing and Feature Engineering\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain the difference between normalization and standardization. When would you use each?\n",
    "2. What are the advantages of using one-hot encoding for categorical variables?\n",
    "3. Describe the process of handling missing data in a dataset.\n",
    "4. How does feature scaling impact the performance of certain machine learning algorithms?\n",
    "\n",
    "**Programming Task: Feature Engineering**\n",
    "\n",
    "Given a dataset with categorical and numerical features (e.g., Titanic dataset), preprocess the data for use in a machine learning model.\n",
    "Tasks include handling missing data, encoding categorical variables, and feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aeeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Data Processing and Feature Engineering\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb71d4",
   "metadata": {},
   "source": [
    "\n",
    "## Dimensionality Reduction: t-SNE and PCA\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain the purpose of t-Distributed Stochastic Neighbor Embedding (t-SNE) and how it differs from PCA.\n",
    "2. What are the main applications of PCA and t-SNE in machine learning?\n",
    "3. Discuss the limitations of t-SNE for large datasets.\n",
    "\n",
    "**Programming Task: t-SNE and PCA Comparison**\n",
    "\n",
    "Use both PCA and t-SNE on the Iris dataset, and visualize the results in a 2D plot. Discuss any differences observed between the two visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for t-SNE and PCA Comparison\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cb4f8",
   "metadata": {},
   "source": [
    "\n",
    "## Hierarchical Clustering\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain the difference between agglomerative and divisive hierarchical clustering.\n",
    "2. What are linkage methods, and why are they important in hierarchical clustering?\n",
    "3. Describe dendrograms and their role in hierarchical clustering.\n",
    "\n",
    "**Programming Task: Hierarchical Clustering**\n",
    "\n",
    "Use hierarchical clustering on the Iris dataset and visualize the clusters using a dendrogram. Experiment with different linkage methods (e.g., single, complete, average) and observe any differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ac0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Hierarchical Clustering and Dendrogram\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28f7dd",
   "metadata": {},
   "source": [
    "\n",
    "## Random Forest\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Describe how a Random Forest algorithm works and its main advantages.\n",
    "2. What are hyperparameters in Random Forest, and how do they affect model performance?\n",
    "3. Explain the concept of feature importance in Random Forest.\n",
    "\n",
    "**Programming Task: Random Forest Classification**\n",
    "\n",
    "Use Random Forest to classify the Iris dataset. Experiment with different numbers of estimators and observe their effect on model accuracy. \n",
    "Plot the feature importances based on the Random Forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Random Forest Classification\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ebe97",
   "metadata": {},
   "source": [
    "\n",
    "## Decision Tree\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. What is a Decision Tree, and how does it make decisions based on data?\n",
    "2. Explain the concepts of information gain and Gini impurity in the context of Decision Trees.\n",
    "3. How can overfitting be mitigated in Decision Trees?\n",
    "\n",
    "**Programming Task: Decision Tree Classification**\n",
    "\n",
    "Use a Decision Tree model to classify the Iris dataset. Experiment with different depth levels for the tree and evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Decision Tree Classification\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a672e",
   "metadata": {},
   "source": [
    "\n",
    "## Support Vector Machine (SVM)\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. What is a Support Vector Machine, and how does it classify data?\n",
    "2. Describe the concept of the margin and support vectors in SVM.\n",
    "3. Explain the differences between linear and non-linear SVMs.\n",
    "\n",
    "**Programming Task: SVM Classification**\n",
    "\n",
    "Use an SVM to classify the Iris dataset. Experiment with different kernels (linear, polynomial, RBF) and observe their impact on model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afa45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for SVM Classification\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1d3b6",
   "metadata": {},
   "source": [
    "\n",
    "## Logistic Regression\n",
    "\n",
    "**Theory Questions**\n",
    "\n",
    "1. Explain how Logistic Regression is used for binary classification.\n",
    "2. What is the sigmoid function, and why is it used in Logistic Regression?\n",
    "3. Describe how regularization (L1, L2) affects Logistic Regression.\n",
    "\n",
    "**Programming Task: Logistic Regression Classification**\n",
    "\n",
    "Use Logistic Regression to classify the digits in the MNIST dataset. Implement regularization and observe its impact on model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f26c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Logistic Regression Classification\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 What is the difference between bias and variance?\n",
    "- **Bias** refers to the error introduced by approximating a complex problem using a simpler model. High bias indicates that the model is too simple and cannot capture the underlying patterns of the data, leading to underfitting.\n",
    "- **Variance** measures how much the model's predictions change when using different training data. High variance indicates that the model is too complex and captures noise in the data, leading to overfitting.\n",
    "\n",
    "#### Practical Implications\n",
    "- A high-bias model, such as a linear regression model for non-linear data, will result in low accuracy on both training and test data.\n",
    "- A high-variance model, such as a deep neural network with insufficient data, will have high accuracy on the training data but low accuracy on the test data.\n",
    "\n",
    "#### Techniques to Address Bias-Variance Tradeoff\n",
    "1. Use regularization techniques like L1 and L2 penalties to reduce variance.\n",
    "2. Increase model complexity or add more features to reduce bias.\n",
    "3. Employ cross-validation techniques to identify the best model complexity.\n"
   ],
   "id": "c0920d9fb713de53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Explain how gradient descent works.\n",
    "**Gradient Descent** is an optimization algorithm used to minimize a function by iteratively moving towards the minimum value of the function. It does this by adjusting the model parameters in the direction of the steepest descent, defined by the negative of the gradient.\n",
    "\n",
    "#### Types of Gradient Descent\n",
    "1. **Batch Gradient Descent**: Uses the entire dataset to compute the gradient. It is computationally expensive for large datasets but provides a stable convergence path.\n",
    "2. **Stochastic Gradient Descent (SGD)**: Uses one data point at a time to compute the gradient. It is computationally efficient but can have noisy updates.\n",
    "3. **Mini-Batch Gradient Descent**: Uses a small batch of data points to compute the gradient. It strikes a balance between the stability of batch gradient descent and the efficiency of SGD.\n",
    "\n",
    "#### Gradient Descent Variants\n",
    "- **Momentum**: Helps accelerate SGD in relevant directions by adding a fraction of the previous update to the current update.\n",
    "- **Adam**: Combines the advantages of both Momentum and RMSProp by maintaining an adaptive learning rate for each parameter."
   ],
   "id": "d9c9316742384b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Programming Challenges\n",
    "\n",
    "### 2.1 Implement Logistic Regression from Scratch\n",
    "Implement a logistic regression model using only NumPy. This exercise tests your understanding of the mathematics behind logistic regression and your ability to translate that into code.\n",
    "\n",
    "#### Mathematical Background\n",
    "The logistic regression model is defined as:\n",
    "\n",
    "$$h(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Where:\n",
    "- \\(z\\) is the linear combination of input features and weights.\n",
    "- The logistic function \\(h(z)\\) maps any real-valued number into the range [0, 1].\n",
    "\n",
    "The model is trained using the **cross-entropy loss** function, which measures the difference between the predicted probability and the actual label.\n"
   ],
   "id": "1a6be1e441266d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Logistic Regression model\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize parameters\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Linear model\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            # Sigmoid function\n",
    "            y_predicted = sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = sigmoid(linear_model)\n",
    "        return [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "\n",
    "# Create a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "id": "a2000edd6771947f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
